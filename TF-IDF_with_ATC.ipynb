{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXTFD3UyANrC",
        "outputId": "258f3759-980c-4fa5-8800-7e886a35798c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: constellate-client in /usr/local/lib/python3.7/dist-packages (0.0.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from constellate-client) (2.23.0)\n",
            "Requirement already satisfied: progressbar in /usr/local/lib/python3.7/dist-packages (from constellate-client) (2.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->constellate-client) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->constellate-client) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->constellate-client) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->constellate-client) (2022.5.18.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install constellate-client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1AfwoWhykeW"
      },
      "source": [
        "# Collecting Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSgZYXOwh32Q",
        "outputId": "5a780832-9aab-40a5-88de-fd37a0049cb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Constellate: use and download of datasets is covered by the Terms & Conditions of Use: https://constellate.org/terms-and-conditions/\n",
            "All documents from JSTOR published in Shakespeare Quarterly from 1950 - 2020. 6745 documents.\n",
            "INFO:root:File /content/data/7e41317e-740f-e86a-4729-20dab492e925-sampled-jsonl.jsonl.gz exists. Not re-downloading.\n"
          ]
        }
      ],
      "source": [
        "# Default dataset is \"Shakespeare Quarterly,\" 1950-present\n",
        "dataset_id = \"7e41317e-740f-e86a-4729-20dab492e925\"\n",
        "\n",
        "# Importing your dataset with a dataset ID\n",
        "import constellate\n",
        "# Pull in the sampled dataset (1500 documents) that matches `dataset_id`\n",
        "# in the form of a gzipped JSON lines file.\n",
        "# The .get_dataset() method downloads the gzipped JSONL file\n",
        "# to the /data folder and returns a string for the file name and location\n",
        "dataset_file = constellate.get_dataset(dataset_id)\n",
        "\n",
        "# To download the full dataset (up to a limit of 25,000 documents),\n",
        "# request it first in the builder environment. See the Constellate Client\n",
        "# documentation at: https://constellate.org/docs/constellate-client\n",
        "# Then use the `constellate.download` method show below.\n",
        "# dataset_file = constellate.download(dataset_id, 'jsonl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM4POYqSwghg"
      },
      "source": [
        "# Apply Pre-Processing Filters (if available)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dj_HNkvHiQ2b",
        "outputId": "d119d55c-5820-4df2-bd86-a3d3eedda8d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "No pre-processed CSV file found. Full dataset will be used.\n"
          ]
        }
      ],
      "source": [
        "# Import a pre-processed CSV file of filtered dataset IDs.\n",
        "# If you do not have a pre-processed CSV file, the analysis\n",
        "# will run on the full dataset and may take longer to complete.\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "pre_processed_file_name = f'data/pre-processed_{dataset_id}.csv'\n",
        "\n",
        "if os.path.exists(pre_processed_file_name):\n",
        "    df = pd.read_csv(pre_processed_file_name)\n",
        "    filtered_id_list = df[\"id\"].tolist()\n",
        "    use_filtered_list = True\n",
        "    print('Pre-Processed CSV found. Successfully read in ' + str(len(df)) + ' documents.')\n",
        "else: \n",
        "    use_filtered_list = False\n",
        "    print('No pre-processed CSV file found. Full dataset will be used.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwkGBxDBwd3A"
      },
      "source": [
        "# Define a Unigram Processing Function\n",
        "\n",
        "In this step, we gather the unigrams. If there is a Pre-Processing Filter, we will only analyze documents from the filtered ID list. We will also process each unigram, assessing them individually. We will complete the following tasks:\n",
        "\n",
        "- Lowercase all tokens\n",
        "\n",
        "- Remove tokens in stopwords list\n",
        "\n",
        "- Remove tokens with fewer than 4 characters\n",
        "\n",
        "- Remove tokens with non-alphabetic characters\n",
        "\n",
        "We can define this process in a function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SnXxu_d7TE7"
      },
      "outputs": [],
      "source": [
        "# Define a function that will process individual tokens\n",
        "# Only a token that passes through all three `if` \n",
        "# statements will be returned. A `True` result for\n",
        "# any `if` statement does not return the token. \n",
        "\n",
        "def process_token(token):\n",
        "    token = token.lower()\n",
        "    if len(token) < 4: # If True, do not return token\n",
        "        return None\n",
        "    if not(token.isalpha()): # If True, do not return token\n",
        "        return None\n",
        "    return token # If all are False, return the lowercased token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1Q7jJSRy-O0"
      },
      "source": [
        "# Collect lists of Document IDs, Titles, and Unigrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "if4Bv9bO7l4K"
      },
      "outputs": [],
      "source": [
        "documents = [] # A list that will contain all of our unigrams\n",
        "document_ids = [] # A list that will contain all of our document ids\n",
        "document_titles = [] # A list that will contain all of our titles\n",
        "\n",
        "for document in constellate.dataset_reader(dataset_file):\n",
        "    processed_document = [] # Temporarily store the unigrams for this document\n",
        "    document_id = document['id'] # Temporarily store the document id for this document\n",
        "    document_title = document['title'] # Temporarily store the document title for this document\n",
        "    if use_filtered_list is True:\n",
        "        # Skip documents not in our filtered_id_list\n",
        "        if document_id not in filtered_id_list:\n",
        "            continue\n",
        "    unigrams = document.get(\"unigramCount\", [])\n",
        "    for gram, count in unigrams.items():\n",
        "        clean_gram = process_token(gram)\n",
        "        if clean_gram is None:\n",
        "            continue\n",
        "        processed_document += [clean_gram] * count # Add the unigram as many times as it was counted\n",
        "    if len(processed_document) > 0:\n",
        "        document_ids.append(document_id)\n",
        "        document_titles.append(document_title)\n",
        "        documents.append(processed_document)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ua7Tkcpo7t8p",
        "outputId": "96f149ef-8a01-484e-812b-c8f3f0c6c30b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review Article\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['social',\n",
              " 'notable',\n",
              " 'discuss',\n",
              " 'voluminous',\n",
              " 'least',\n",
              " 'least',\n",
              " 'distillation',\n",
              " 'have',\n",
              " 'have',\n",
              " 'since',\n",
              " 'hope',\n",
              " 'never',\n",
              " 'never',\n",
              " 'prob',\n",
              " 'spite',\n",
              " 'among',\n",
              " 'rare',\n",
              " 'dealt',\n",
              " 'actually',\n",
              " 'taking',\n",
              " 'taking',\n",
              " 'truer',\n",
              " 'evolved',\n",
              " 'competitor',\n",
              " 'education',\n",
              " 'pressure',\n",
              " 'excellence',\n",
              " 'cambridge',\n",
              " 'students',\n",
              " 'fashionable',\n",
              " 'shakespeare',\n",
              " 'shakespeare',\n",
              " 'usher',\n",
              " 'study',\n",
              " 'essential',\n",
              " 'guneratne',\n",
              " 'tradition',\n",
              " 'intervals',\n",
              " 'harshly',\n",
              " 'organization',\n",
              " 'consider',\n",
              " 'historiographers',\n",
              " 'female',\n",
              " 'operations',\n",
              " 'reviews',\n",
              " 'considering',\n",
              " 'shows',\n",
              " 'participants',\n",
              " 'established',\n",
              " 'denigrating',\n",
              " 'synchronized',\n",
              " 'only',\n",
              " 'only',\n",
              " 'before',\n",
              " 'chronology',\n",
              " 'times',\n",
              " 'treatment',\n",
              " 'archaeopteryx',\n",
              " 'entirely',\n",
              " 'entirely',\n",
              " 'screened',\n",
              " 'might',\n",
              " 'even',\n",
              " 'even',\n",
              " 'even',\n",
              " 'fail',\n",
              " 'response',\n",
              " 'interest',\n",
              " 'interest',\n",
              " 'falsifies',\n",
              " 'method',\n",
              " 'talents',\n",
              " 'that',\n",
              " 'that',\n",
              " 'that',\n",
              " 'that',\n",
              " 'that',\n",
              " 'that',\n",
              " 'that',\n",
              " 'that',\n",
              " 'that',\n",
              " 'that',\n",
              " 'that',\n",
              " 'that',\n",
              " 'that',\n",
              " 'that',\n",
              " 'asta',\n",
              " 'action',\n",
              " 'contributions',\n",
              " 'tomime',\n",
              " 'ance',\n",
              " 'theater',\n",
              " 'decisive',\n",
              " 'buchanans',\n",
              " 'five',\n",
              " 'robert',\n",
              " 'german',\n",
              " 'german',\n",
              " 'amplifications',\n",
              " 'unremitting',\n",
              " 'slim',\n",
              " 'goes',\n",
              " 'contemporary',\n",
              " 'much',\n",
              " 'much',\n",
              " 'much',\n",
              " 'much',\n",
              " 'much',\n",
              " 'shake',\n",
              " 'shake',\n",
              " 'already',\n",
              " 'surviving',\n",
              " 'surviving',\n",
              " 'order',\n",
              " 'larger',\n",
              " 'contain',\n",
              " 'discussions',\n",
              " 'evolution',\n",
              " 'film',\n",
              " 'film',\n",
              " 'posing',\n",
              " 'examples',\n",
              " 'examples',\n",
              " 'harvard',\n",
              " 'stripe',\n",
              " 'latter',\n",
              " 'work',\n",
              " 'work',\n",
              " 'work',\n",
              " 'usual',\n",
              " 'local',\n",
              " 'making',\n",
              " 'assortment',\n",
              " 'assortment',\n",
              " 'codify',\n",
              " 'were',\n",
              " 'history',\n",
              " 'history',\n",
              " 'history',\n",
              " 'version',\n",
              " 'version',\n",
              " 'version',\n",
              " 'version',\n",
              " 'weimar',\n",
              " 'treats',\n",
              " 'treats',\n",
              " 'narrators',\n",
              " 'claims',\n",
              " 'commemora',\n",
              " 'volume',\n",
              " 'become',\n",
              " 'else',\n",
              " 'material',\n",
              " 'period',\n",
              " 'period',\n",
              " 'period',\n",
              " 'period',\n",
              " 'california',\n",
              " 'quartet',\n",
              " 'rearguard',\n",
              " 'earlier',\n",
              " 'dwells',\n",
              " 'dwells',\n",
              " 'celebrated',\n",
              " 'celebrated',\n",
              " 'celebrated',\n",
              " 'will',\n",
              " 'supplement',\n",
              " 'insistence',\n",
              " 'singular',\n",
              " 'explanatory',\n",
              " 'expanding',\n",
              " 'double',\n",
              " 'first',\n",
              " 'first',\n",
              " 'inhabited',\n",
              " 'pictorial',\n",
              " 'literature',\n",
              " 'adaptations',\n",
              " 'adaptations',\n",
              " 'adaptations',\n",
              " 'adaptations',\n",
              " 'adaptations',\n",
              " 'concentrat',\n",
              " 'favorite',\n",
              " 'every',\n",
              " 'every',\n",
              " 'cally',\n",
              " 'reverse',\n",
              " 'contribution',\n",
              " 'receive',\n",
              " 'lighting',\n",
              " 'approximate',\n",
              " 'ways',\n",
              " 'throughout',\n",
              " 'would',\n",
              " 'would',\n",
              " 'would',\n",
              " 'would',\n",
              " 'arguments',\n",
              " 'emil',\n",
              " 'michel',\n",
              " 'treat',\n",
              " 'treat',\n",
              " 'advanced',\n",
              " 'dickens',\n",
              " 'stagecraft',\n",
              " 'hamlet',\n",
              " 'hamlet',\n",
              " 'modernity',\n",
              " 'contrast',\n",
              " 'assayed',\n",
              " 'remnant',\n",
              " 'numerous',\n",
              " 'plished',\n",
              " 'what',\n",
              " 'obvious',\n",
              " 'circumspect',\n",
              " 'late',\n",
              " 'late',\n",
              " 'sharply',\n",
              " 'companies',\n",
              " 'presentations',\n",
              " 'more',\n",
              " 'scholars',\n",
              " 'scholars',\n",
              " 'deficiencies',\n",
              " 'lost',\n",
              " 'lost',\n",
              " 'conventional',\n",
              " 'achievements',\n",
              " 'achievements',\n",
              " 'practices',\n",
              " 'anthony',\n",
              " 'anthony',\n",
              " 'ones',\n",
              " 'media',\n",
              " 'films',\n",
              " 'films',\n",
              " 'films',\n",
              " 'films',\n",
              " 'films',\n",
              " 'films',\n",
              " 'films',\n",
              " 'attached',\n",
              " 'phase',\n",
              " 'unsurpassed',\n",
              " 'despite',\n",
              " 'accounts',\n",
              " 'ball',\n",
              " 'ball',\n",
              " 'ball',\n",
              " 'ball',\n",
              " 'alimentary',\n",
              " 'preserved',\n",
              " 'henny',\n",
              " 'with',\n",
              " 'with',\n",
              " 'with',\n",
              " 'with',\n",
              " 'with',\n",
              " 'with',\n",
              " 'with',\n",
              " 'with',\n",
              " 'with',\n",
              " 'with',\n",
              " 'assume',\n",
              " 'british',\n",
              " 'british',\n",
              " 'ruggero',\n",
              " 'university',\n",
              " 'fleshing',\n",
              " 'while',\n",
              " 'while',\n",
              " 'romeo',\n",
              " 'facets',\n",
              " 'hand',\n",
              " 'significant',\n",
              " 'recycled',\n",
              " 'well',\n",
              " 'monumental',\n",
              " 'greater',\n",
              " 'silent',\n",
              " 'silent',\n",
              " 'accurate',\n",
              " 'slides',\n",
              " 'catalogues',\n",
              " 'award',\n",
              " 'methods',\n",
              " 'fanciful',\n",
              " 'appropriating',\n",
              " 'bore',\n",
              " 'death',\n",
              " 'field',\n",
              " 'gave',\n",
              " 'though',\n",
              " 'embodies',\n",
              " 'acceptance',\n",
              " 'transition',\n",
              " 'remain',\n",
              " 'odds',\n",
              " 'made',\n",
              " 'made',\n",
              " 'each',\n",
              " 'stems',\n",
              " 'deplorably',\n",
              " 'number',\n",
              " 'number',\n",
              " 'something',\n",
              " 'coincided',\n",
              " 'tenor',\n",
              " 'vitagraph',\n",
              " 'many',\n",
              " 'devoted',\n",
              " 'periodization',\n",
              " 'preliminary',\n",
              " 'bergmans',\n",
              " 'tures',\n",
              " 'complained',\n",
              " 'deserves',\n",
              " 'frederick',\n",
              " 'griffith',\n",
              " 'provincial',\n",
              " 'historical',\n",
              " 'rival',\n",
              " 'appeared',\n",
              " 'appeared',\n",
              " 'account',\n",
              " 'some',\n",
              " 'some',\n",
              " 'some',\n",
              " 'outstanding',\n",
              " 'narrative',\n",
              " 'narrative',\n",
              " 'narrative',\n",
              " 'quarterly',\n",
              " 'quarterly',\n",
              " 'more',\n",
              " 'more',\n",
              " 'more',\n",
              " 'more',\n",
              " 'more',\n",
              " 'more',\n",
              " 'exhibitions',\n",
              " 'nicholas',\n",
              " 'nicholas',\n",
              " 'exclusively',\n",
              " 'whatever',\n",
              " 'nicely',\n",
              " 'hardly',\n",
              " 'cinema',\n",
              " 'motion',\n",
              " 'richer',\n",
              " 'there',\n",
              " 'indication',\n",
              " 'godzillas',\n",
              " 'versions',\n",
              " 'versions',\n",
              " 'versions',\n",
              " 'still',\n",
              " 'still',\n",
              " 'film',\n",
              " 'film',\n",
              " 'film',\n",
              " 'film',\n",
              " 'film',\n",
              " 'film',\n",
              " 'film',\n",
              " 'film',\n",
              " 'film',\n",
              " 'film',\n",
              " 'film',\n",
              " 'film',\n",
              " 'illustrative',\n",
              " 'accom',\n",
              " 'appropriates',\n",
              " 'appear',\n",
              " 'united',\n",
              " 'united',\n",
              " 'plays',\n",
              " 'plays',\n",
              " 'spoken',\n",
              " 'american',\n",
              " 'italian',\n",
              " 'italian',\n",
              " 'subtly',\n",
              " 'treating',\n",
              " 'stomp',\n",
              " 'generation',\n",
              " 'recognition',\n",
              " 'recognition',\n",
              " 'began',\n",
              " 'practi',\n",
              " 'caesar',\n",
              " 'states',\n",
              " 'states',\n",
              " 'approach',\n",
              " 'approach',\n",
              " 'approach',\n",
              " 'performing',\n",
              " 'efforts',\n",
              " 'equivocal',\n",
              " 'fourth',\n",
              " 'purportedly',\n",
              " 'succeeds',\n",
              " 'variety',\n",
              " 'intended',\n",
              " 'down',\n",
              " 'down',\n",
              " 'their',\n",
              " 'their',\n",
              " 'their',\n",
              " 'system',\n",
              " 'historians',\n",
              " 'from',\n",
              " 'reinvigorates',\n",
              " 'explain',\n",
              " 'reprised',\n",
              " 'beyond',\n",
              " 'this',\n",
              " 'this',\n",
              " 'this',\n",
              " 'this',\n",
              " 'academy',\n",
              " 'discusses',\n",
              " 'charmingly',\n",
              " 'early',\n",
              " 'early',\n",
              " 'through',\n",
              " 'studies',\n",
              " 'porten',\n",
              " 'business',\n",
              " 'lacking',\n",
              " 'when',\n",
              " 'king',\n",
              " 'prints',\n",
              " 'stage',\n",
              " 'scholarly',\n",
              " 'cartel',\n",
              " 'attempts',\n",
              " 'classic',\n",
              " 'transitional',\n",
              " 'merchant',\n",
              " 'gained',\n",
              " 'gained',\n",
              " 'western',\n",
              " 'grant',\n",
              " 'precursor',\n",
              " 'subtitle',\n",
              " 'subtitle',\n",
              " 'subtitle',\n",
              " 'prod',\n",
              " 'come',\n",
              " 'which',\n",
              " 'which',\n",
              " 'which',\n",
              " 'which',\n",
              " 'which',\n",
              " 'afterword',\n",
              " 'vardac',\n",
              " 'vardac',\n",
              " 'succeeding',\n",
              " 'both',\n",
              " 'chapters',\n",
              " 'chapters',\n",
              " 'palgrave',\n",
              " 'crafted',\n",
              " 'crafted',\n",
              " 'clever',\n",
              " 'cinema',\n",
              " 'cinema',\n",
              " 'remotely',\n",
              " 'folger',\n",
              " 'previously',\n",
              " 'recruits',\n",
              " 'performances',\n",
              " 'broaden',\n",
              " 'cinematic',\n",
              " 'cinematic',\n",
              " 'cinematic',\n",
              " 'pearson',\n",
              " 'thought',\n",
              " 'articulate',\n",
              " 'benefit',\n",
              " 'clusters',\n",
              " 'choosing',\n",
              " 'comprehensive',\n",
              " 'influenced',\n",
              " 'talkative',\n",
              " 'chapter',\n",
              " 'chapter',\n",
              " 'chapter',\n",
              " 'into',\n",
              " 'into',\n",
              " 'into',\n",
              " 'into',\n",
              " 'into',\n",
              " 'into',\n",
              " 'asides',\n",
              " 'canonical',\n",
              " 'second',\n",
              " 'expressionist',\n",
              " 'different',\n",
              " 'different',\n",
              " 'different',\n",
              " 'richard',\n",
              " 'richard',\n",
              " 'thus',\n",
              " 'foucault',\n",
              " 'europe',\n",
              " 'appellation',\n",
              " 'opposite',\n",
              " 'novelizations',\n",
              " 'abundance',\n",
              " 'long',\n",
              " 'case',\n",
              " 'craftily',\n",
              " 'most',\n",
              " 'most',\n",
              " 'speare',\n",
              " 'speare',\n",
              " 'speare',\n",
              " 'indicative',\n",
              " 'indicative',\n",
              " 'johnston',\n",
              " 'disjunc',\n",
              " 'excess',\n",
              " 'exported',\n",
              " 'silent',\n",
              " 'dumb',\n",
              " 'perspectives',\n",
              " 'theatrical',\n",
              " 'defense',\n",
              " 'culture',\n",
              " 'visual',\n",
              " 'mean',\n",
              " 'less',\n",
              " 'disclaimers',\n",
              " 'hunting',\n",
              " 'departure',\n",
              " 'credentials',\n",
              " 'spoof',\n",
              " 'realism',\n",
              " 'linear',\n",
              " 'book',\n",
              " 'later',\n",
              " 'later',\n",
              " 'than',\n",
              " 'than',\n",
              " 'than',\n",
              " 'domestic',\n",
              " 'summation',\n",
              " 'embedded',\n",
              " 'three',\n",
              " 'three',\n",
              " 'medium',\n",
              " 'garrick',\n",
              " 'stars',\n",
              " 'overplayed',\n",
              " 'tions',\n",
              " 'frugoni',\n",
              " 'pathes',\n",
              " 'excluded',\n",
              " 'citizen',\n",
              " 'quotes',\n",
              " 'corrective',\n",
              " 'industries',\n",
              " 'revision',\n",
              " 'constitutes',\n",
              " 'witnessing',\n",
              " 'issued',\n",
              " 'achievement',\n",
              " 'popular',\n",
              " 'rash',\n",
              " 'reviewed',\n",
              " 'revival',\n",
              " 'used',\n",
              " 'presumed',\n",
              " 'julius',\n",
              " 'moments',\n",
              " 'purloined',\n",
              " 'shape',\n",
              " 'effect',\n",
              " 'having',\n",
              " 'there',\n",
              " 'been',\n",
              " 'been',\n",
              " 'been',\n",
              " 'within',\n",
              " 'shakespeare',\n",
              " 'shakespeare',\n",
              " 'shakespeare',\n",
              " 'shakespeare',\n",
              " 'shakespeare',\n",
              " 'shakespeare',\n",
              " 'shakespeare',\n",
              " 'shakespeare',\n",
              " 'shakespeare',\n",
              " 'shakespeare',\n",
              " 'shakespeare',\n",
              " 'casual',\n",
              " 'concentrates',\n",
              " 'materials',\n",
              " 'illustrating',\n",
              " 'pathe',\n",
              " 'diverse',\n",
              " 'from',\n",
              " 'from',\n",
              " 'from',\n",
              " 'from',\n",
              " 'from',\n",
              " 'from',\n",
              " 'history',\n",
              " 'enormous',\n",
              " 'formance',\n",
              " 'european',\n",
              " 'terrain',\n",
              " 'national',\n",
              " 'tercentenary',\n",
              " 'star',\n",
              " 'theatrical',\n",
              " 'correction',\n",
              " 'attitude',\n",
              " 'certainly',\n",
              " 'both',\n",
              " 'anticipated',\n",
              " 'original',\n",
              " 'view',\n",
              " 'synetic',\n",
              " 'prototype',\n",
              " 'picture',\n",
              " 'contingen',\n",
              " 'time',\n",
              " 'brief',\n",
              " 'serve',\n",
              " 'judith',\n",
              " 'judith',\n",
              " 'judith',\n",
              " 'demands',\n",
              " 'unknown',\n",
              " 'hundred',\n",
              " 'trade',\n",
              " 'proves',\n",
              " 'being',\n",
              " 'xxiii',\n",
              " 'bombast',\n",
              " 'fulfilling',\n",
              " 'snugly',\n",
              " 'flow',\n",
              " 'sifting',\n",
              " 'having',\n",
              " 'implications',\n",
              " 'high',\n",
              " 'high',\n",
              " 'cies',\n",
              " 'reifies',\n",
              " 'limitations',\n",
              " 'dominant',\n",
              " 'arsenio',\n",
              " 'appears',\n",
              " 'mercifully',\n",
              " 'fitting',\n",
              " 'acknowledge',\n",
              " 'distinct',\n",
              " 'about',\n",
              " 'buchanan',\n",
              " 'buchanan',\n",
              " 'buchanan',\n",
              " 'buchanan',\n",
              " 'buchanan',\n",
              " 'although',\n",
              " 'decidedly',\n",
              " 'grand',\n",
              " 'overstatement',\n",
              " 'attendant',\n",
              " 'comparison',\n",
              " 'othello',\n",
              " 'during',\n",
              " 'during',\n",
              " 'organized',\n",
              " 'eccentric',\n",
              " 'burden',\n",
              " 'certain',\n",
              " 'experiment',\n",
              " 'title',\n",
              " 'those',\n",
              " 'those',\n",
              " 'those',\n",
              " 'description',\n",
              " 'busily',\n",
              " 'such',\n",
              " 'such',\n",
              " 'intense',\n",
              " 'series',\n",
              " 'accommodated',\n",
              " 'introduction',\n",
              " 'restricted',\n",
              " 'points',\n",
              " 'cultures',\n",
              " 'priority',\n",
              " 'such',\n",
              " 'important',\n",
              " 'hamilton',\n",
              " 'contains',\n",
              " 'success',\n",
              " 'excellent',\n",
              " 'seems',\n",
              " 'world',\n",
              " 'world',\n",
              " 'these',\n",
              " 'these',\n",
              " 'curiously',\n",
              " 'giving',\n",
              " 'additional',\n",
              " 'exist',\n",
              " 'epitaph',\n",
              " 'shallow']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Show the unigrams collected for a particular document\n",
        "# Change the value of n to see a different document\n",
        "n = 0\n",
        "\n",
        "print(document_titles[n])\n",
        "list(documents[n])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLQMZnQi7-dx",
        "outputId": "39efd24d-354b-46c5-a4cf-f8efcdda0315"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('with', 12),\n",
              " ('gentle', 6),\n",
              " ('have', 5),\n",
              " ('that', 5),\n",
              " ('shakespeare', 4),\n",
              " ('jupiter', 4),\n",
              " ('this', 4),\n",
              " ('rosalind', 4),\n",
              " ('most', 4),\n",
              " ('name', 4),\n",
              " ('first', 4),\n",
              " ('orlando', 4),\n",
              " ('scene', 3),\n",
              " ('reading', 3),\n",
              " ('when', 3),\n",
              " ('ganymede', 3),\n",
              " ('good', 2),\n",
              " ('next', 2),\n",
              " ('folio', 2),\n",
              " ('half', 2),\n",
              " ('modern', 2),\n",
              " ('feel', 2),\n",
              " ('lovemaking', 2),\n",
              " ('texts', 2),\n",
              " ('your', 2)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Convert a given document into a Counter object to determine\n",
        "# word frequencies count\n",
        "\n",
        "# Import counter to help count word frequencies\n",
        "from collections import Counter\n",
        "\n",
        "word_freq = Counter(documents[1]) # Change documents index to see a different document\n",
        "word_freq.most_common(25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxFjWevp0LHt"
      },
      "source": [
        "# Using Gensim to Compute â€œTerm Frequency- Inverse Document Frequency\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6N8h2NA0TtN"
      },
      "source": [
        "# Creating a Gensim Dictionary\n",
        "\n",
        "A gensim dictionary is a kind of masterlist of all the words across all the documents in our corpus. Each unique word is assigned an ID in the gensim dictionary. The result is a set of key/value pairs of unique tokens and their unique IDs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWIFl7Rh0Mhc",
        "outputId": "e22ad8b8-ff78-4cac-ac91-27f8eaa476d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:summarizer.preprocessing.cleaner:'pattern' package not found; tag filters are not available for English\n",
            "INFO:gensim.corpora.dictionary:adding document #0 to Dictionary(0 unique tokens: [])\n",
            "INFO:gensim.corpora.dictionary:built Dictionary(96666 unique tokens: ['about', 'abundance', 'academy', 'acceptance', 'accom']...) from 1499 documents (total 2055259 corpus positions)\n"
          ]
        }
      ],
      "source": [
        "import gensim\n",
        "dictionary = gensim.corpora.Dictionary(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiWmfvG30lFW"
      },
      "source": [
        "The gensim dictionary stores a unique identifier (starting with 0) for every unique token in the corpus. The gensim dictionary does not contain information on word frequencies; it only catalogs all the unique words in the corpus. You can see the unique ID for each token in the text using the .token2id() method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzRqhIOl0Red",
        "outputId": "9271b6f8-4f12-4d75-c338-a8794eb1db82"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('about', 0),\n",
              " ('abundance', 1),\n",
              " ('academy', 2),\n",
              " ('acceptance', 3),\n",
              " ('accom', 4),\n",
              " ('accommodated', 5),\n",
              " ('account', 6),\n",
              " ('accounts', 7),\n",
              " ('accurate', 8),\n",
              " ('achievement', 9),\n",
              " ('achievements', 10),\n",
              " ('acknowledge', 11),\n",
              " ('action', 12),\n",
              " ('actually', 13),\n",
              " ('adaptations', 14),\n",
              " ('additional', 15),\n",
              " ('advanced', 16),\n",
              " ('afterword', 17),\n",
              " ('alimentary', 18),\n",
              " ('already', 19),\n",
              " ('although', 20),\n",
              " ('american', 21),\n",
              " ('among', 22),\n",
              " ('amplifications', 23),\n",
              " ('ance', 24),\n",
              " ('anthony', 25),\n",
              " ('anticipated', 26),\n",
              " ('appear', 27),\n",
              " ('appeared', 28),\n",
              " ('appears', 29),\n",
              " ('appellation', 30),\n",
              " ('approach', 31),\n",
              " ('appropriates', 32),\n",
              " ('appropriating', 33),\n",
              " ('approximate', 34),\n",
              " ('archaeopteryx', 35),\n",
              " ('arguments', 36),\n",
              " ('arsenio', 37),\n",
              " ('articulate', 38),\n",
              " ('asides', 39),\n",
              " ('assayed', 40),\n",
              " ('assortment', 41),\n",
              " ('assume', 42),\n",
              " ('asta', 43),\n",
              " ('attached', 44),\n",
              " ('attempts', 45),\n",
              " ('attendant', 46),\n",
              " ('attitude', 47),\n",
              " ('award', 48),\n",
              " ('ball', 49),\n",
              " ('become', 50),\n",
              " ('been', 51),\n",
              " ('before', 52),\n",
              " ('began', 53),\n",
              " ('being', 54),\n",
              " ('benefit', 55),\n",
              " ('bergmans', 56),\n",
              " ('beyond', 57),\n",
              " ('bombast', 58),\n",
              " ('book', 59),\n",
              " ('bore', 60),\n",
              " ('both', 61),\n",
              " ('brief', 62),\n",
              " ('british', 63),\n",
              " ('broaden', 64),\n",
              " ('buchanan', 65),\n",
              " ('buchanans', 66),\n",
              " ('burden', 67),\n",
              " ('busily', 68),\n",
              " ('business', 69),\n",
              " ('caesar', 70),\n",
              " ('california', 71),\n",
              " ('cally', 72),\n",
              " ('cambridge', 73),\n",
              " ('canonical', 74),\n",
              " ('cartel', 75),\n",
              " ('case', 76),\n",
              " ('casual', 77),\n",
              " ('catalogues', 78),\n",
              " ('celebrated', 79),\n",
              " ('certain', 80),\n",
              " ('certainly', 81),\n",
              " ('chapter', 82),\n",
              " ('chapters', 83),\n",
              " ('charmingly', 84),\n",
              " ('choosing', 85),\n",
              " ('chronology', 86),\n",
              " ('cies', 87),\n",
              " ('cinema', 88),\n",
              " ('cinematic', 89),\n",
              " ('circumspect', 90),\n",
              " ('citizen', 91),\n",
              " ('claims', 92),\n",
              " ('classic', 93),\n",
              " ('clever', 94),\n",
              " ('clusters', 95),\n",
              " ('codify', 96),\n",
              " ('coincided', 97),\n",
              " ('come', 98),\n",
              " ('commemora', 99),\n",
              " ('companies', 100),\n",
              " ('comparison', 101),\n",
              " ('competitor', 102),\n",
              " ('complained', 103),\n",
              " ('comprehensive', 104),\n",
              " ('concentrat', 105),\n",
              " ('concentrates', 106),\n",
              " ('consider', 107),\n",
              " ('considering', 108),\n",
              " ('constitutes', 109),\n",
              " ('contain', 110),\n",
              " ('contains', 111),\n",
              " ('contemporary', 112),\n",
              " ('contingen', 113),\n",
              " ('contrast', 114),\n",
              " ('contribution', 115),\n",
              " ('contributions', 116),\n",
              " ('conventional', 117),\n",
              " ('correction', 118),\n",
              " ('corrective', 119),\n",
              " ('crafted', 120),\n",
              " ('craftily', 121),\n",
              " ('credentials', 122),\n",
              " ('culture', 123),\n",
              " ('cultures', 124),\n",
              " ('curiously', 125),\n",
              " ('dealt', 126),\n",
              " ('death', 127),\n",
              " ('decidedly', 128),\n",
              " ('decisive', 129),\n",
              " ('defense', 130),\n",
              " ('deficiencies', 131),\n",
              " ('demands', 132),\n",
              " ('denigrating', 133),\n",
              " ('departure', 134),\n",
              " ('deplorably', 135),\n",
              " ('description', 136),\n",
              " ('deserves', 137),\n",
              " ('despite', 138),\n",
              " ('devoted', 139),\n",
              " ('dickens', 140),\n",
              " ('different', 141),\n",
              " ('disclaimers', 142),\n",
              " ('discuss', 143),\n",
              " ('discusses', 144),\n",
              " ('discussions', 145),\n",
              " ('disjunc', 146),\n",
              " ('distillation', 147),\n",
              " ('distinct', 148),\n",
              " ('diverse', 149),\n",
              " ('domestic', 150),\n",
              " ('dominant', 151),\n",
              " ('double', 152),\n",
              " ('down', 153),\n",
              " ('dumb', 154),\n",
              " ('during', 155),\n",
              " ('dwells', 156),\n",
              " ('each', 157),\n",
              " ('earlier', 158),\n",
              " ('early', 159),\n",
              " ('eccentric', 160),\n",
              " ('education', 161),\n",
              " ('effect', 162),\n",
              " ('efforts', 163),\n",
              " ('else', 164),\n",
              " ('embedded', 165),\n",
              " ('embodies', 166),\n",
              " ('emil', 167),\n",
              " ('enormous', 168),\n",
              " ('entirely', 169),\n",
              " ('epitaph', 170),\n",
              " ('equivocal', 171),\n",
              " ('essential', 172),\n",
              " ('established', 173),\n",
              " ('europe', 174),\n",
              " ('european', 175),\n",
              " ('even', 176),\n",
              " ('every', 177),\n",
              " ('evolution', 178),\n",
              " ('evolved', 179),\n",
              " ('examples', 180),\n",
              " ('excellence', 181),\n",
              " ('excellent', 182),\n",
              " ('excess', 183),\n",
              " ('excluded', 184),\n",
              " ('exclusively', 185),\n",
              " ('exhibitions', 186),\n",
              " ('exist', 187),\n",
              " ('expanding', 188),\n",
              " ('experiment', 189),\n",
              " ('explain', 190),\n",
              " ('explanatory', 191),\n",
              " ('exported', 192),\n",
              " ('expressionist', 193),\n",
              " ('facets', 194),\n",
              " ('fail', 195),\n",
              " ('falsifies', 196),\n",
              " ('fanciful', 197),\n",
              " ('fashionable', 198),\n",
              " ('favorite', 199),\n",
              " ('female', 200),\n",
              " ('field', 201),\n",
              " ('film', 202),\n",
              " ('films', 203),\n",
              " ('first', 204),\n",
              " ('fitting', 205),\n",
              " ('five', 206),\n",
              " ('fleshing', 207),\n",
              " ('flow', 208),\n",
              " ('folger', 209),\n",
              " ('formance', 210),\n",
              " ('foucault', 211),\n",
              " ('fourth', 212),\n",
              " ('frederick', 213),\n",
              " ('from', 214),\n",
              " ('frugoni', 215),\n",
              " ('fulfilling', 216),\n",
              " ('gained', 217),\n",
              " ('garrick', 218),\n",
              " ('gave', 219),\n",
              " ('generation', 220),\n",
              " ('german', 221),\n",
              " ('giving', 222),\n",
              " ('godzillas', 223),\n",
              " ('goes', 224),\n",
              " ('grand', 225),\n",
              " ('grant', 226),\n",
              " ('greater', 227),\n",
              " ('griffith', 228),\n",
              " ('guneratne', 229),\n",
              " ('hamilton', 230),\n",
              " ('hamlet', 231),\n",
              " ('hand', 232),\n",
              " ('hardly', 233),\n",
              " ('harshly', 234),\n",
              " ('harvard', 235),\n",
              " ('have', 236),\n",
              " ('having', 237),\n",
              " ('henny', 238),\n",
              " ('high', 239),\n",
              " ('historians', 240),\n",
              " ('historical', 241),\n",
              " ('historiographers', 242),\n",
              " ('history', 243),\n",
              " ('hope', 244),\n",
              " ('hundred', 245),\n",
              " ('hunting', 246),\n",
              " ('illustrating', 247),\n",
              " ('illustrative', 248),\n",
              " ('implications', 249),\n",
              " ('important', 250),\n",
              " ('indication', 251),\n",
              " ('indicative', 252),\n",
              " ('industries', 253),\n",
              " ('influenced', 254),\n",
              " ('inhabited', 255),\n",
              " ('insistence', 256),\n",
              " ('intended', 257),\n",
              " ('intense', 258),\n",
              " ('interest', 259),\n",
              " ('intervals', 260),\n",
              " ('into', 261),\n",
              " ('introduction', 262),\n",
              " ('issued', 263),\n",
              " ('italian', 264),\n",
              " ('johnston', 265),\n",
              " ('judith', 266),\n",
              " ('julius', 267),\n",
              " ('king', 268),\n",
              " ('lacking', 269),\n",
              " ('larger', 270),\n",
              " ('late', 271),\n",
              " ('later', 272),\n",
              " ('latter', 273),\n",
              " ('least', 274),\n",
              " ('less', 275),\n",
              " ('lighting', 276),\n",
              " ('limitations', 277),\n",
              " ('linear', 278),\n",
              " ('literature', 279),\n",
              " ('local', 280),\n",
              " ('long', 281),\n",
              " ('lost', 282),\n",
              " ('made', 283),\n",
              " ('making', 284),\n",
              " ('many', 285),\n",
              " ('material', 286),\n",
              " ('materials', 287),\n",
              " ('mean', 288),\n",
              " ('media', 289),\n",
              " ('medium', 290),\n",
              " ('merchant', 291),\n",
              " ('mercifully', 292),\n",
              " ('method', 293),\n",
              " ('methods', 294),\n",
              " ('michel', 295),\n",
              " ('might', 296),\n",
              " ('modernity', 297),\n",
              " ('moments', 298),\n",
              " ('monumental', 299),\n",
              " ('more', 300),\n",
              " ('most', 301),\n",
              " ('motion', 302),\n",
              " ('much', 303),\n",
              " ('narrative', 304),\n",
              " ('narrators', 305),\n",
              " ('national', 306),\n",
              " ('never', 307),\n",
              " ('nicely', 308),\n",
              " ('nicholas', 309),\n",
              " ('notable', 310),\n",
              " ('novelizations', 311),\n",
              " ('number', 312),\n",
              " ('numerous', 313),\n",
              " ('obvious', 314),\n",
              " ('odds', 315),\n",
              " ('ones', 316),\n",
              " ('only', 317),\n",
              " ('operations', 318),\n",
              " ('opposite', 319),\n",
              " ('order', 320),\n",
              " ('organization', 321),\n",
              " ('organized', 322),\n",
              " ('original', 323),\n",
              " ('othello', 324),\n",
              " ('outstanding', 325),\n",
              " ('overplayed', 326),\n",
              " ('overstatement', 327),\n",
              " ('palgrave', 328),\n",
              " ('participants', 329),\n",
              " ('pathe', 330),\n",
              " ('pathes', 331),\n",
              " ('pearson', 332),\n",
              " ('performances', 333),\n",
              " ('performing', 334),\n",
              " ('period', 335),\n",
              " ('periodization', 336),\n",
              " ('perspectives', 337),\n",
              " ('phase', 338),\n",
              " ('pictorial', 339),\n",
              " ('picture', 340),\n",
              " ('plays', 341),\n",
              " ('plished', 342),\n",
              " ('points', 343),\n",
              " ('popular', 344),\n",
              " ('porten', 345),\n",
              " ('posing', 346),\n",
              " ('practi', 347),\n",
              " ('practices', 348),\n",
              " ('precursor', 349),\n",
              " ('preliminary', 350),\n",
              " ('presentations', 351),\n",
              " ('preserved', 352),\n",
              " ('pressure', 353),\n",
              " ('presumed', 354),\n",
              " ('previously', 355),\n",
              " ('prints', 356),\n",
              " ('priority', 357),\n",
              " ('prob', 358),\n",
              " ('prod', 359),\n",
              " ('prototype', 360),\n",
              " ('proves', 361),\n",
              " ('provincial', 362),\n",
              " ('purloined', 363),\n",
              " ('purportedly', 364),\n",
              " ('quarterly', 365),\n",
              " ('quartet', 366),\n",
              " ('quotes', 367),\n",
              " ('rare', 368),\n",
              " ('rash', 369),\n",
              " ('realism', 370),\n",
              " ('rearguard', 371),\n",
              " ('receive', 372),\n",
              " ('recognition', 373),\n",
              " ('recruits', 374),\n",
              " ('recycled', 375),\n",
              " ('reifies', 376),\n",
              " ('reinvigorates', 377),\n",
              " ('remain', 378),\n",
              " ('remnant', 379),\n",
              " ('remotely', 380),\n",
              " ('reprised', 381),\n",
              " ('response', 382),\n",
              " ('restricted', 383),\n",
              " ('reverse', 384),\n",
              " ('reviewed', 385),\n",
              " ('reviews', 386),\n",
              " ('revision', 387),\n",
              " ('revival', 388),\n",
              " ('richard', 389),\n",
              " ('richer', 390),\n",
              " ('rival', 391),\n",
              " ('robert', 392),\n",
              " ('romeo', 393),\n",
              " ('ruggero', 394),\n",
              " ('scholarly', 395),\n",
              " ('scholars', 396),\n",
              " ('screened', 397),\n",
              " ('second', 398),\n",
              " ('seems', 399),\n",
              " ('series', 400),\n",
              " ('serve', 401),\n",
              " ('shake', 402),\n",
              " ('shakespeare', 403),\n",
              " ('shallow', 404),\n",
              " ('shape', 405),\n",
              " ('sharply', 406),\n",
              " ('shows', 407),\n",
              " ('sifting', 408),\n",
              " ('significant', 409),\n",
              " ('silent', 410),\n",
              " ('since', 411),\n",
              " ('singular', 412),\n",
              " ('slides', 413),\n",
              " ('slim', 414),\n",
              " ('snugly', 415),\n",
              " ('social', 416),\n",
              " ('some', 417),\n",
              " ('something', 418),\n",
              " ('speare', 419),\n",
              " ('spite', 420),\n",
              " ('spoken', 421),\n",
              " ('spoof', 422),\n",
              " ('stage', 423),\n",
              " ('stagecraft', 424),\n",
              " ('star', 425),\n",
              " ('stars', 426),\n",
              " ('states', 427),\n",
              " ('stems', 428),\n",
              " ('still', 429),\n",
              " ('stomp', 430),\n",
              " ('stripe', 431),\n",
              " ('students', 432),\n",
              " ('studies', 433),\n",
              " ('study', 434),\n",
              " ('subtitle', 435),\n",
              " ('subtly', 436),\n",
              " ('succeeding', 437),\n",
              " ('succeeds', 438),\n",
              " ('success', 439),\n",
              " ('such', 440),\n",
              " ('summation', 441),\n",
              " ('supplement', 442),\n",
              " ('surviving', 443),\n",
              " ('synchronized', 444),\n",
              " ('synetic', 445),\n",
              " ('system', 446),\n",
              " ('taking', 447),\n",
              " ('talents', 448),\n",
              " ('talkative', 449),\n",
              " ('tenor', 450),\n",
              " ('tercentenary', 451),\n",
              " ('terrain', 452),\n",
              " ('than', 453),\n",
              " ('that', 454),\n",
              " ('theater', 455),\n",
              " ('theatrical', 456),\n",
              " ('their', 457),\n",
              " ('there', 458),\n",
              " ('these', 459),\n",
              " ('this', 460),\n",
              " ('those', 461),\n",
              " ('though', 462),\n",
              " ('thought', 463),\n",
              " ('three', 464),\n",
              " ('through', 465),\n",
              " ('throughout', 466),\n",
              " ('thus', 467),\n",
              " ('time', 468),\n",
              " ('times', 469),\n",
              " ('tions', 470),\n",
              " ('title', 471),\n",
              " ('tomime', 472),\n",
              " ('trade', 473),\n",
              " ('tradition', 474),\n",
              " ('transition', 475),\n",
              " ('transitional', 476),\n",
              " ('treat', 477),\n",
              " ('treating', 478),\n",
              " ('treatment', 479),\n",
              " ('treats', 480),\n",
              " ('truer', 481),\n",
              " ('tures', 482),\n",
              " ('united', 483),\n",
              " ('university', 484),\n",
              " ('unknown', 485),\n",
              " ('unremitting', 486),\n",
              " ('unsurpassed', 487),\n",
              " ('used', 488),\n",
              " ('usher', 489),\n",
              " ('usual', 490),\n",
              " ('vardac', 491),\n",
              " ('variety', 492),\n",
              " ('version', 493),\n",
              " ('versions', 494),\n",
              " ('view', 495),\n",
              " ('visual', 496),\n",
              " ('vitagraph', 497),\n",
              " ('volume', 498),\n",
              " ('voluminous', 499),\n",
              " ('ways', 500),\n",
              " ('weimar', 501),\n",
              " ('well', 502),\n",
              " ('were', 503),\n",
              " ('western', 504),\n",
              " ('what', 505),\n",
              " ('whatever', 506),\n",
              " ('when', 507),\n",
              " ('which', 508),\n",
              " ('while', 509),\n",
              " ('will', 510),\n",
              " ('with', 511),\n",
              " ('within', 512),\n",
              " ('witnessing', 513),\n",
              " ('work', 514),\n",
              " ('world', 515),\n",
              " ('would', 516),\n",
              " ('xxiii', 517),\n",
              " ('according', 518),\n",
              " ('acts', 519),\n",
              " ('affection', 520),\n",
              " ('after', 521),\n",
              " ('again', 522),\n",
              " ('agree', 523),\n",
              " ('allusions', 524),\n",
              " ('amusing', 525),\n",
              " ('appearance', 526),\n",
              " ('association', 527),\n",
              " ('assured', 528),\n",
              " ('atomies', 529),\n",
              " ('audience', 530),\n",
              " ('call', 531),\n",
              " ('called', 532),\n",
              " ('celia', 533),\n",
              " ('central', 534),\n",
              " ('characterization', 535),\n",
              " ('charm', 536),\n",
              " ('command', 537),\n",
              " ('comment', 538),\n",
              " ('complete', 539),\n",
              " ('consistent', 540),\n",
              " ('count', 541),\n",
              " ('dealing', 542),\n",
              " ('deification', 543),\n",
              " ('delightfully', 544),\n",
              " ('demeaning', 545),\n",
              " ('development', 546),\n",
              " ('discovered', 547),\n",
              " ('disguise', 548),\n",
              " ('dropped', 549),\n",
              " ('drops', 550),\n",
              " ('duces', 551),\n",
              " ('easy', 552),\n",
              " ('edited', 553),\n",
              " ('editors', 554),\n",
              " ('ellen', 555),\n",
              " ('emendation', 556),\n",
              " ('emended', 557),\n",
              " ('emphasized', 558),\n",
              " ('emphasizes', 559),\n",
              " ('exhaustive', 560),\n",
              " ('existence', 561),\n",
              " ('face', 562),\n",
              " ('fancying', 563),\n",
              " ('fashionableness', 564),\n",
              " ('feel', 565),\n",
              " ('finding', 566),\n",
              " ('folio', 567),\n",
              " ('forest', 568),\n",
              " ('forth', 569),\n",
              " ('found', 570),\n",
              " ('four', 571),\n",
              " ('full', 572),\n",
              " ('ganymede', 573),\n",
              " ('gentle', 574),\n",
              " ('gives', 575),\n",
              " ('good', 576),\n",
              " ('half', 577),\n",
              " ('haphazard', 578),\n",
              " ('hardin', 579),\n",
              " ('here', 580),\n",
              " ('herself', 581),\n",
              " ('homilie', 582),\n",
              " ('identification', 583),\n",
              " ('identifies', 584),\n",
              " ('imagery', 585),\n",
              " ('imaginal', 586),\n",
              " ('immediately', 587),\n",
              " ('implicit', 588),\n",
              " ('includes', 589),\n",
              " ('inconsistent', 590),\n",
              " ('ingenuous', 591),\n",
              " ('intimates', 592),\n",
              " ('jove', 593),\n",
              " ('jupiter', 594),\n",
              " ('kentucky', 595),\n",
              " ('knows', 596),\n",
              " ('liance', 597),\n",
              " ('lies', 598),\n",
              " ('like', 599),\n",
              " ('limited', 600),\n",
              " ('lind', 601),\n",
              " ('line', 602),\n",
              " ('list', 603),\n",
              " ('logic', 604),\n",
              " ('longingly', 605),\n",
              " ('look', 606),\n",
              " ('love', 607),\n",
              " ('lovemaking', 608),\n",
              " ('lover', 609),\n",
              " ('makes', 610),\n",
              " ('mary', 611),\n",
              " ('masculine', 612),\n",
              " ('means', 613),\n",
              " ('mention', 614),\n",
              " ('mock', 615),\n",
              " ('modern', 616),\n",
              " ('motif', 617),\n",
              " ('must', 618),\n",
              " ('name', 619),\n",
              " ('near', 620),\n",
              " ('need', 621),\n",
              " ('neither', 622),\n",
              " ('next', 623),\n",
              " ('notes', 624),\n",
              " ('notices', 625),\n",
              " ('orlando', 626),\n",
              " ('oxford', 627),\n",
              " ('parishioners', 628),\n",
              " ('part', 629),\n",
              " ('passion', 630),\n",
              " ('patience', 631),\n",
              " ('persistent', 632),\n",
              " ('perspective', 633),\n",
              " ('phrases', 634),\n",
              " ('pocket', 635),\n",
              " ('possibly', 636),\n",
              " ('prepare', 637),\n",
              " ('propositions', 638),\n",
              " ('purports', 639),\n",
              " ('queries', 640),\n",
              " ('quick', 641),\n",
              " ('rather', 642),\n",
              " ('read', 643),\n",
              " ('reading', 644),\n",
              " ('readings', 645),\n",
              " ('reception', 646),\n",
              " ('reduce', 647),\n",
              " ('references', 648),\n",
              " ('regarded', 649),\n",
              " ('relationship', 650),\n",
              " ('relevance', 651),\n",
              " ('relish', 652),\n",
              " ('remark', 653),\n",
              " ('remember', 654),\n",
              " ('resolution', 655),\n",
              " ('resolve', 656),\n",
              " ('retain', 657),\n",
              " ('retaining', 658),\n",
              " ('rickey', 659),\n",
              " ('rightness', 660),\n",
              " ('rise', 661),\n",
              " ('rosalind', 662),\n",
              " ('scene', 663),\n",
              " ('scenes', 664),\n",
              " ('sense', 665),\n",
              " ('shepherds', 666),\n",
              " ('shortly', 667),\n",
              " ('significance', 668),\n",
              " ('sisson', 669),\n",
              " ('situation', 670),\n",
              " ('slightly', 671),\n",
              " ('smack', 672),\n",
              " ('somewhat', 673),\n",
              " ('suggests', 674),\n",
              " ('supposedly', 675),\n",
              " ('surely', 676),\n",
              " ('swears', 677),\n",
              " ('symbol', 678),\n",
              " ('take', 679),\n",
              " ('taste', 680),\n",
              " ('tedious', 681),\n",
              " ('texts', 682),\n",
              " ('them', 683),\n",
              " ('then', 684),\n",
              " ('therefore', 685),\n",
              " ('thinks', 686),\n",
              " ('third', 687),\n",
              " ('tree', 688),\n",
              " ('true', 689),\n",
              " ('tucker', 690),\n",
              " ('turns', 691),\n",
              " ('tutor', 692),\n",
              " ('under', 693),\n",
              " ('understanding', 694),\n",
              " ('upon', 695),\n",
              " ('using', 696),\n",
              " ('verses', 697),\n",
              " ('wearied', 698),\n",
              " ('weary', 699),\n",
              " ('whole', 700),\n",
              " ('wittily', 701),\n",
              " ('womanly', 702),\n",
              " ('worse', 703),\n",
              " ('yale', 704),\n",
              " ('your', 705),\n",
              " ('above', 706),\n",
              " ('abstracted', 707),\n",
              " ('accompanied', 708),\n",
              " ('addison', 709),\n",
              " ('addressed', 710),\n",
              " ('administered', 711),\n",
              " ('alan', 712),\n",
              " ('alcuni', 713),\n",
              " ('allinea', 714),\n",
              " ('also', 715),\n",
              " ('america', 716),\n",
              " ('amherst', 717),\n",
              " ('andrea', 718),\n",
              " ('andrews', 719),\n",
              " ('anne', 720),\n",
              " ('anni', 721),\n",
              " ('antony', 722),\n",
              " ('arnold', 723),\n",
              " ('articles', 724),\n",
              " ('arts', 725),\n",
              " ('ashton', 726),\n",
              " ('assistant', 727),\n",
              " ('astington', 728),\n",
              " ('auchincloss', 729),\n",
              " ('austin', 730),\n",
              " ('autumn', 731),\n",
              " ('available', 732),\n",
              " ('back', 733),\n",
              " ('barbara', 734),\n",
              " ('barker', 735),\n",
              " ('barry', 736),\n",
              " ('barton', 737),\n",
              " ('beckerman', 738),\n",
              " ('bentley', 739),\n",
              " ('bergeron', 740),\n",
              " ('berkeley', 741),\n",
              " ('bernard', 742),\n",
              " ('berry', 743),\n",
              " ('between', 744),\n",
              " ('bevington', 745),\n",
              " ('bibliografia', 746),\n",
              " ('bibliographer', 747),\n",
              " ('bibliography', 748),\n",
              " ('biblioteca', 749),\n",
              " ('birthplace', 750),\n",
              " ('board', 751),\n",
              " ('booth', 752),\n",
              " ('boxill', 753),\n",
              " ('bregoli', 754),\n",
              " ('brooks', 755),\n",
              " ('calderwood', 756),\n",
              " ('capitol', 757),\n",
              " ('casa', 758),\n",
              " ('casella', 759),\n",
              " ('catalogo', 760),\n",
              " ('catalogue', 761),\n",
              " ('censimento', 762),\n",
              " ('cerasano', 763),\n",
              " ('chapel', 764),\n",
              " ('charles', 765),\n",
              " ('charney', 766),\n",
              " ('check', 767),\n",
              " ('chicago', 768),\n",
              " ('circulation', 769),\n",
              " ('city', 770),\n",
              " ('coleman', 771),\n",
              " ('college', 772),\n",
              " ('columbia', 773),\n",
              " ('comedies', 774),\n",
              " ('commentary', 775),\n",
              " ('communications', 776),\n",
              " ('conservate', 777),\n",
              " ('cook', 778),\n",
              " ('copies', 779),\n",
              " ('correspondence', 780),\n",
              " ('costituisce', 781),\n",
              " ('cover', 782),\n",
              " ('cunningham', 783),\n",
              " ('current', 784),\n",
              " ('cyrus', 785),\n",
              " ('dalziel', 786),\n",
              " ('david', 787),\n",
              " ('degli', 788),\n",
              " ('democratic', 789),\n",
              " ('dennis', 790),\n",
              " ('dessen', 791),\n",
              " ('discovering', 792),\n",
              " ('dissemination', 793),\n",
              " ('doebler', 794),\n",
              " ('dolora', 795),\n",
              " ('drama', 796),\n",
              " ('dramma', 797),\n",
              " ('drawing', 798),\n",
              " ('eades', 799),\n",
              " ('east', 800),\n",
              " ('edition', 801),\n",
              " ('editor', 802),\n",
              " ('editori', 803),\n",
              " ('editorial', 804),\n",
              " ('editrice', 805),\n",
              " ('edwards', 806),\n",
              " ('eileen', 807),\n",
              " ('elmer', 808),\n",
              " ('elocution', 809),\n",
              " ('emergence', 810),\n",
              " ('england', 811),\n",
              " ('english', 812),\n",
              " ('engraved', 813),\n",
              " ('entered', 814),\n",
              " ('envelope', 815),\n",
              " ('episode', 816),\n",
              " ('eric', 817),\n",
              " ('esistenti', 818),\n",
              " ('essays', 819),\n",
              " ('evans', 820),\n",
              " ('examination', 821),\n",
              " ('exchequer', 822),\n",
              " ('executive', 823),\n",
              " ('existed', 824),\n",
              " ('faces', 825),\n",
              " ('festival', 826),\n",
              " ('filone', 827),\n",
              " ('firenze', 828),\n",
              " ('fonte', 829),\n",
              " ('foreign', 830),\n",
              " ('form', 831),\n",
              " ('founded', 832),\n",
              " ('frey', 833),\n",
              " ('further', 834),\n",
              " ('geoffrey', 835),\n",
              " ('gerald', 836),\n",
              " ('gilbert', 837),\n",
              " ('globe', 838),\n",
              " ('grammaticus', 839),\n",
              " ('granville', 840),\n",
              " ('graphics', 841),\n",
              " ('guide', 842),\n",
              " ('gundersheimer', 843),\n",
              " ('gunter', 844),\n",
              " ('habicht', 845),\n",
              " ('hakespeare', 846),\n",
              " ('harley', 847),\n",
              " ('harold', 848),\n",
              " ('harper', 849),\n",
              " ('harrison', 850),\n",
              " ('harry', 851),\n",
              " ('hill', 852),\n",
              " ('holdings', 853),\n",
              " ('homer', 854),\n",
              " ('honour', 855),\n",
              " ('howard', 856),\n",
              " ('humanities', 857),\n",
              " ('illinois', 858),\n",
              " ('include', 859),\n",
              " ('included', 860),\n",
              " ('independent', 861),\n",
              " ('index', 862),\n",
              " ('indexed', 863),\n",
              " ('individual', 864),\n",
              " ('individuals', 865),\n",
              " ('information', 866),\n",
              " ('inside', 867),\n",
              " ('institutional', 868),\n",
              " ('institutions', 869),\n",
              " ('instrument', 870),\n",
              " ('intern', 871),\n",
              " ('international', 872),\n",
              " ('irwin', 873),\n",
              " ('ishrat', 874),\n",
              " ('issn', 875),\n",
              " ('issue', 876),\n",
              " ('issues', 877),\n",
              " ('italiani', 878),\n",
              " ('italiano', 879),\n",
              " ('jacobson', 880),\n",
              " ('james', 881),\n",
              " ('jeanne', 882),\n",
              " ('jennalie', 883),\n",
              " ('john', 884),\n",
              " ('jorge', 885),\n",
              " ('joseph', 886),\n",
              " ('july', 887),\n",
              " ('kansas', 888),\n",
              " ('kenneth', 889),\n",
              " ('kimbrough', 890),\n",
              " ('knachel', 891),\n",
              " ('lear', 892),\n",
              " ('levi', 893),\n",
              " ('levin', 894),\n",
              " ('library', 895),\n",
              " ('libri', 896),\n",
              " ('life', 897),\n",
              " ('lindblad', 898),\n",
              " ('lire', 899),\n",
              " ('literary', 900),\n",
              " ('loewenwarter', 901),\n",
              " ('lopere', 902),\n",
              " ('loro', 903),\n",
              " ('louise', 904),\n",
              " ('lucy', 905),\n",
              " ('magic', 906),\n",
              " ('manager', 907),\n",
              " ('marvin', 908),\n",
              " ('maryland', 909),\n",
              " ('matter', 910),\n",
              " ('mauda', 911),\n",
              " ('maurice', 912),\n",
              " ('meant', 913),\n",
              " ('meredith', 914),\n",
              " ('meserole', 915),\n",
              " ('metadrama', 916),\n",
              " ('metaphor', 917),\n",
              " ('michael', 918),\n",
              " ('michigan', 919),\n",
              " ('microfilms', 920),\n",
              " ('milton', 921),\n",
              " ('money', 922),\n",
              " ('muir', 923),\n",
              " ('myth', 924),\n",
              " ('nautical', 925),\n",
              " ('negli', 926),\n",
              " ('nelle', 927),\n",
              " ('nora', 928),\n",
              " ('north', 929),\n",
              " ('northrop', 930),\n",
              " ('office', 931),\n",
              " ('olschki', 932),\n",
              " ('options', 933),\n",
              " ('ordered', 934),\n",
              " ('orders', 935),\n",
              " ('oregon', 936),\n",
              " ('other', 937),\n",
              " ('ottawa', 938),\n",
              " ('outside', 939),\n",
              " ('painting', 940),\n",
              " ('paradox', 941),\n",
              " ('patti', 942),\n",
              " ('paul', 943),\n",
              " ('payable', 944),\n",
              " ('pennsylvania', 945),\n",
              " ('perseguita', 946),\n",
              " ('peter', 947),\n",
              " ('philip', 948),\n",
              " ('phyllis', 949),\n",
              " ('play', 950),\n",
              " ('playhouse', 951),\n",
              " ('playing', 952),\n",
              " ('poetry', 953),\n",
              " ('port', 954),\n",
              " ('post', 955),\n",
              " ('postale', 956),\n",
              " ('press', 957),\n",
              " ('price', 958),\n",
              " ('princeton', 959),\n",
              " ('printed', 960),\n",
              " ('printers', 961),\n",
              " ('problem', 962),\n",
              " ('production', 963),\n",
              " ('produzione', 964),\n",
              " ('providing', 965),\n",
              " ('publication', 966),\n",
              " ('published', 967),\n",
              " ('quel', 968),\n",
              " ('quest', 969),\n",
              " ('questo', 970),\n",
              " ('ralph', 971),\n",
              " ('rapporti', 972),\n",
              " ('rates', 973),\n",
              " ('readiness', 974),\n",
              " ('reflections', 975),\n",
              " ('regenstein', 976),\n",
              " ('regular', 977),\n",
              " ('reinhardt', 978),\n",
              " ('relations', 979),\n",
              " ('renai', 980),\n",
              " ('renaissance', 981),\n",
              " ('reprints', 982),\n",
              " ('republic', 983),\n",
              " ('research', 984),\n",
              " ('return', 985),\n",
              " ('rice', 986),\n",
              " ('ricerca', 987),\n",
              " ('roberts', 988),\n",
              " ('rochester', 989),\n",
              " ('roger', 990),\n",
              " ('rolf', 991),\n",
              " ('romantic', 992),\n",
              " ('ronald', 993),\n",
              " ('rosenberg', 994),\n",
              " ('rossky', 995),\n",
              " ('russell', 996),\n",
              " ('russo', 997),\n",
              " ('rutgers', 998),\n",
              " ('saccio', 999),\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "list(dictionary.token2id.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuy2Px2f0fWF",
        "outputId": "966b8149-8bfe-4a42-bc0c-6ed7720f0925"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2391"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Get the value for the key 'people'. Return 0 if there is no token matching 'people'. \n",
        "# The number returned is the gensim dictionary ID for the token. \n",
        "\n",
        "dictionary.token2id.get('people', 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXMj_-Hc0vWc",
        "outputId": "7b26d138-76d1-4144-f9cc-7d2e353a1d20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "people\n"
          ]
        }
      ],
      "source": [
        "# Find the token associated with a token id number\n",
        "token_id = 2391\n",
        "\n",
        "# If the token id matches, print out the associated token\n",
        "for dict_id, token in dictionary.items():\n",
        "    if dict_id == token_id:\n",
        "        print(token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIfaJ3_G1By8"
      },
      "source": [
        "# Creating a Bag of Words Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJw-Pfje09S0",
        "outputId": "2cc7b672-73d7-4f28-ffa7-9b927db43875"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag of words corpus created successfully.\n"
          ]
        }
      ],
      "source": [
        "# Create a bag of words corpus\n",
        "bow_corpus = []\n",
        "\n",
        "for document in documents:\n",
        "    bow_corpus.append(dictionary.doc2bow(document))\n",
        "\n",
        "print('Bag of words corpus created successfully.')\n",
        "\n",
        "# The for loop could also be written as a list comprehension\n",
        "# bow_corpus = [dictionary.doc2bow(document) for document in documents]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KogE0W-2laU",
        "outputId": "f9651e68-c1fb-4287-c71b-bb3884ad474f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(69, 1),\n",
              " (209, 2),\n",
              " (365, 3),\n",
              " (403, 6),\n",
              " (511, 1),\n",
              " (527, 1),\n",
              " (542, 1),\n",
              " (710, 1),\n",
              " (716, 1),\n",
              " (780, 2),\n",
              " (802, 1),\n",
              " (832, 1),\n",
              " (895, 2),\n",
              " (900, 1),\n",
              " (937, 2),\n",
              " (966, 1),\n",
              " (967, 1),\n",
              " (1011, 2),\n",
              " (1777, 2),\n",
              " (1903, 1),\n",
              " (2082, 1),\n",
              " (2456, 2),\n",
              " (3433, 1),\n",
              " (4095, 1),\n",
              " (4909, 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Examine the bag of words corpus for a specific document n\n",
        "# Change the value of n to see another document\n",
        "n = 50\n",
        "\n",
        "list(bow_corpus[n][:25]) # List out a slice of the first 25 items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHGyz2LB2ojD",
        "outputId": "8cf72e86-4f6e-4e49-e07c-8b10b9403717"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "business                  1\n",
            "folger                    2\n",
            "quarterly                 3\n",
            "shakespeare               6\n",
            "with                      1\n",
            "association               1\n",
            "dealing                   1\n",
            "addressed                 1\n",
            "america                   1\n",
            "correspondence            2\n",
            "editor                    1\n",
            "founded                   1\n",
            "library                   2\n",
            "literary                  1\n",
            "other                     2\n",
            "publication               1\n",
            "published                 1\n",
            "should                    2\n",
            "matters                   2\n",
            "same                      1\n",
            "books                     1\n",
            "sent                      2\n",
            "review                    1\n",
            "accepted                  1\n",
            "offered                   1\n",
            "relating                  1\n",
            "manuscripts               2\n",
            "patricia                  1\n",
            "subscriptions             1\n"
          ]
        }
      ],
      "source": [
        "# For each id and count in the bag of words corpus\n",
        "# Print the corresponding word from the Gensim dictionary and count\n",
        "for id, count in bow_corpus[n]:\n",
        "    print(dictionary[id].ljust(25), count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac2jfB973wSE"
      },
      "source": [
        "# Create the TfidfModel\n",
        "\n",
        "The next step is to create the TF-IDF model which will set the parameters for our implementation of TF-IDF. In our TF-IDF example, the formula for TF-IDF was:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fx4XUs9g3DRM",
        "outputId": "2d81cad3-415a-46ba-ff00-a76c0435fd26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:gensim.models.tfidfmodel:collecting document frequencies\n",
            "INFO:gensim.models.tfidfmodel:PROGRESS: processing document #0\n",
            "INFO:gensim.models.tfidfmodel:calculating IDF weights for 1499 documents and 96665 features (965947 matrix non-zeros)\n"
          ]
        }
      ],
      "source": [
        "# Create our gensim TF-IDF model\n",
        "model = gensim.models.TfidfModel(corpus=bow_corpus, smartirs='atc')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rq1LPyse4Sac"
      },
      "outputs": [],
      "source": [
        "# Create TF-IDF scores for the ``bow_corpus`` using our model\n",
        "corpus_tfidf = model[bow_corpus]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efujFISE4iBD",
        "outputId": "ff3fc450-97b8-455a-d4bc-dee644ae4a09"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 0.004165359318460266),\n",
              " (1, 0.05273152277773158),\n",
              " (2, 0.03896359725500704),\n",
              " (3, 0.03249886655811404),\n",
              " (4, 0.07677324222557771),\n",
              " (5, 0.05534224658180443),\n",
              " (6, 0.014382272407544904),\n",
              " (7, 0.027113784416215946),\n",
              " (8, 0.0373379713845312),\n",
              " (9, 0.03620665872940413),\n",
              " (10, 0.0491437025430276),\n",
              " (11, 0.03344972020380123),\n",
              " (12, 0.016698377189814092),\n",
              " (13, 0.0212699539322715),\n",
              " (14, 0.04509821793214101),\n",
              " (15, 0.026893808282929015),\n",
              " (16, 0.034346331097227095),\n",
              " (17, 0.050577386719316234),\n",
              " (18, 0.07677324222557771),\n",
              " (19, 0.01735223344771443),\n",
              " (20, 0.012660105724594202),\n",
              " (21, 0.019753429292405013),\n",
              " (22, 0.012142896457206141),\n",
              " (23, 0.08178276354379453),\n",
              " (24, 0.04477049198716163)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# List out the TF-IDF scores for the nth document's first 10 tokens\n",
        "# Change n to change the document\n",
        "n = 0\n",
        "\n",
        "list(corpus_tfidf[n][:25])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQv-NQKU49zs",
        "outputId": "65df6d0f-2d12-4ff4-fa2d-2fc2f03c1177"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "about                0.004165359318460266\n",
            "abundance            0.05273152277773158\n",
            "academy              0.03896359725500704\n",
            "acceptance           0.03249886655811404\n",
            "accom                0.07677324222557771\n",
            "accommodated         0.05534224658180443\n",
            "account              0.014382272407544904\n",
            "accounts             0.027113784416215946\n",
            "accurate             0.0373379713845312\n",
            "achievement          0.03620665872940413\n",
            "achievements         0.0491437025430276\n",
            "acknowledge          0.03344972020380123\n",
            "action               0.016698377189814092\n",
            "actually             0.0212699539322715\n",
            "adaptations          0.04509821793214101\n",
            "additional           0.026893808282929015\n",
            "advanced             0.034346331097227095\n",
            "afterword            0.050577386719316234\n",
            "alimentary           0.07677324222557771\n",
            "already              0.01735223344771443\n",
            "although             0.012660105724594202\n",
            "american             0.019753429292405013\n",
            "among                0.012142896457206141\n",
            "amplifications       0.08178276354379453\n",
            "ance                 0.04477049198716163\n"
          ]
        }
      ],
      "source": [
        "# Display the tokens instead of the gensim dictionary IDs.\n",
        "for id, score in corpus_tfidf[n][:25]:\n",
        "    print(dictionary[id].ljust(20), score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkXHL9I356XS"
      },
      "source": [
        "# Find Top Terms in a Single Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X--IrBQQ565S",
        "outputId": "4e65aeb0-5f0b-4de8-f109-4ecd2bf4ede3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title:  Review Article\n",
            "ID:  http://www.jstor.org/stable/23025656\n",
            "----------------------------------------\n",
            "vardac               0.09636970325498885\n",
            "archaeopteryx        0.09034659680155203\n",
            "arsenio              0.09034659680155203\n",
            "bergmans             0.09034659680155203\n",
            "commemora            0.09034659680155203\n",
            "concentrat           0.09034659680155203\n",
            "contingen            0.09034659680155203\n",
            "disjunc              0.09034659680155203\n",
            "falsifies            0.09034659680155203\n",
            "frugoni              0.09034659680155203\n",
            "godzillas            0.09034659680155203\n",
            "guneratne            0.09034659680155203\n",
            "novelizations        0.09034659680155203\n",
            "pathe                0.09034659680155203\n",
            "porten               0.09034659680155203\n",
            "practi               0.09034659680155203\n",
            "rearguard            0.09034659680155203\n",
            "synetic              0.09034659680155203\n",
            "vitagraph            0.09034659680155203\n",
            "buchanan             0.08189645623582076\n"
          ]
        }
      ],
      "source": [
        "# Sort the tuples in our tf-idf scores list\n",
        "\n",
        "# Choosing a document by its index number\n",
        "# Change n to see a different document\n",
        "n = 0\n",
        "\n",
        "def Sort(tfidf_tuples):\n",
        "    \"This sorts based on the second value in our tuple, the tf-idf score\"\n",
        "    tfidf_tuples.sort(key = lambda x: x[1], reverse=True)\n",
        "    return tfidf_tuples \n",
        "\n",
        "# Print the document id and title\n",
        "print('Title: ', document_titles[n])\n",
        "print('ID: ', document_ids[n])\n",
        "print('----------------------------------------')\n",
        "\n",
        "# List the top twenty tokens in our example document by their TF-IDF scores\n",
        "# First we sort the tokens with their scores\n",
        "most_significant_terms = Sort(corpus_tfidf[n])[:20]\n",
        "\n",
        "# Next we print the list, replacing the token ids with the tokens\n",
        "for id, score in most_significant_terms:\n",
        "    print(dictionary[id].ljust(20), score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJZbkULJ6tDj"
      },
      "source": [
        "We also analyze across the entire corpus to find the most unique terms. These are terms that appear in a particular text, but rarely or never appear in other texts. (Often, these will be proper names since a particular article may mention a name often but the name may rarely appear in other articles. Thereâ€™s also a fairly good chance these will be typos or errors in optical character recognition.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRO4i_pn6F7z"
      },
      "outputs": [],
      "source": [
        "td = {}\n",
        "for document in corpus_tfidf:\n",
        "    for token_id, score in document:\n",
        "        current_score = td.get(dictionary.get(token_id), 0)\n",
        "        if current_score < score:\n",
        "            td.update([(dictionary.get(token_id), score)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBwu2Mq96yvk",
        "outputId": "b0470abb-c178-4e76-d07c-4a2d9466e1b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cwtrnca              0.9777852589476882\n",
            "terence              0.9498900312074794\n",
            "nuimber              0.8319747660464009\n",
            "tuft                 0.7868376014650895\n",
            "emblemata            0.7852131956320808\n",
            "ouderdom             0.7766128344659354\n",
            "wenceslaus           0.7639576845819294\n",
            "gaiicanus            0.7601563052782292\n",
            "reproducedfrmtefgr   0.7572397678450393\n",
            "dicus                0.7265126251019742\n",
            "houwelyck            0.6967260500651924\n",
            "hrotsvits            0.6912337411707761\n",
            "gibraltar            0.6631087398173557\n",
            "comediae             0.6456051905232666\n",
            "penshurst            0.6366533423710458\n",
            "duodekas             0.6325106929571689\n",
            "emblematum           0.6325106929571689\n",
            "jike                 0.6313999059233509\n",
            "evenyng              0.6293035863369911\n",
            "mornyng              0.6293035863369911\n",
            "alcmena              0.6252388155874612\n",
            "amphitryo            0.6252388155874612\n",
            "captivi              0.6206171107588102\n",
            "johan                0.6192255141749697\n",
            "dormitory            0.6090366868084331\n"
          ]
        }
      ],
      "source": [
        "# Sort the items of ``td`` into a new variable ``sorted_td``\n",
        "# the ``reverse`` starts from highest to lowest\n",
        "sorted_td = sorted(td.items(), key=lambda kv: kv[1], reverse=True) \n",
        "\n",
        "for term, weight in sorted_td[:25]: # Print the top 25 terms in the entire corpus\n",
        "    print(term.ljust(20), weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLVi-n3A7BJb"
      },
      "source": [
        "# Display Most Significant Term for each Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQjOoetz61i7",
        "outputId": "13643a8a-3120-4856-b58f-0b0ef81adb3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "http://www.jstor.org/stable/23025656 vardac 0.09636970325498885\n",
            "http://www.jstor.org/stable/2866842 atomies 0.16414829725545108\n",
            "http://www.jstor.org/stable/2870361 ishrat 0.09742685996867113\n",
            "http://www.jstor.org/stable/2869042 birbeck 0.08884924780770011\n",
            "http://www.jstor.org/stable/2866396 recitative 0.08891242784008163\n",
            "http://www.jstor.org/stable/2868260 auff 0.0706386429797704\n",
            "http://www.jstor.org/stable/2866945 fhall 0.10940495221853316\n",
            "http://www.jstor.org/stable/2866486 tarras 0.14019047478795563\n",
            "http://www.jstor.org/stable/2870020 moriarty 0.0839037873576494\n",
            "http://www.jstor.org/stable/2867158 mavortio 0.19436992001388878\n",
            "http://www.jstor.org/stable/2868374 viliam 0.07751320685198493\n"
          ]
        }
      ],
      "source": [
        "# For each document, print the ID, most significant/unique word, and TF/IDF score\n",
        "\n",
        "n = 0\n",
        "\n",
        "for n, doc in enumerate(corpus_tfidf):\n",
        "    if len(doc) < 1:\n",
        "        continue\n",
        "    word_id, score = max(doc, key=lambda x: x[1])\n",
        "    print(document_ids[n], dictionary.get(word_id), score)\n",
        "    if n >= 10:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjwJ_IkC7LlT"
      },
      "source": [
        "# Ranking documents by TF-IDF Score for a Search Word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bB2StzM7FEz"
      },
      "outputs": [],
      "source": [
        "# Set a limit on the number of documents analyzed\n",
        "limit = 1000\n",
        "\n",
        "from collections import defaultdict\n",
        "terms_to_docs = defaultdict(list)\n",
        "for doc_id, doc in enumerate(corpus_tfidf):\n",
        "    for term_id, value in doc:\n",
        "        term = dictionary.get(term_id)\n",
        "        terms_to_docs[term].append((doc_id, value))\n",
        "    if doc_id >= limit:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUCeKIDu7NmS",
        "outputId": "4c460914-7309-47bb-e79b-ec5f4c56b771"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Front Matter                                       0.07233120491971268\n",
            "Review Article                                     0.06992737046641462\n",
            "Review Article                                     0.06175695973766614\n",
            "Review Article                                     0.05481377815152557\n",
            "The Great Lakes Shakespeare Festival               0.05260194079913104\n",
            "Review Article                                     0.0523969885483399\n",
            "Front Matter                                       0.051669346840501076\n",
            "Review Article                                     0.050001972055823504\n",
            "The New Arden Coriolanus                           0.04874219511638209\n",
            "Now Then, Now Then, What's Going on Here?          0.048729668040474586\n",
            "Notes and Comments                                 0.046098952115329515\n",
            "Review Article                                     0.04413483928415584\n",
            "Front Matter                                       0.042208706494066855\n",
            "Review Article                                     0.04086851827888139\n",
            "Shakespeare and Chapman                            0.03966468310466985\n",
            "Volume Information                                 0.03894013087862546\n",
            "Prince Henry Stuart Defamed                        0.03839332232855489\n",
            "In Praise of Two Eminent Shakespeareans            0.03829104914616684\n",
            "Price-tags and Trade-offs: Chivalry and the Shakespearean Hero in 1985 0.03806569857647404\n",
            "Shakespearean Metastance                           0.037974018981021145\n",
            "Review Article                                     0.03687406086695882\n",
            "Review Article                                     0.035210695229881156\n",
            "Shakespeare's Tragic Frontier                      0.03509515644072113\n",
            "Back Matter                                        0.03423722716395417\n",
            "Review Article                                     0.03383401894441583\n",
            "Review Article                                     0.03370023588825384\n",
            "Review Article                                     0.03352988534312094\n",
            "Shakespeare for Teachers                           0.03337078668383863\n",
            "Review Article                                     0.03321795447745598\n",
            "Volume Information                                 0.03249994615330757\n",
            "The Reviewer as Historian                          0.03235146557453199\n",
            "Shakespeare and Legendary History: Lear and Cymbeline 0.030052251087135932\n",
            "New York Shakespeare Festival, Lincoln Center, 1973-74 0.029845750373388588\n",
            "A New Transparency Or an Old Elitism?              0.029747334526507806\n",
            "Language, Linguistics, Philology                   0.029099744523058566\n",
            "Volume Information                                 0.02905057348185171\n",
            "Shakespeare on the New York Stage, 1955-1956       0.028153097206008292\n",
            "Volume Information                                 0.027589474663601756\n",
            "Current Theater Notes                              0.027579911399693503\n",
            "The Wooing of Lady Anne: A Psychological Inquiry   0.026356136517384807\n",
            "Back Matter                                        0.026112933921843755\n",
            "Play Groups                                        0.02582785284974095\n",
            "Volume Information                                 0.025695661538460205\n",
            "A German Producer's Hamlet                         0.02504333988438858\n",
            "The Body of the Actor in \"Coriolanus\"              0.02492808474029946\n",
            "Irving in Shakespeare: Interpretation or Creation? 0.02424665094950212\n",
            "Fools, Fowls, and Perttaunt-Like in Love's Labour's Lost 0.024115027667205163\n",
            "Oregon Shakespearean Festival                      0.023790031489308257\n",
            "Eighteenth-Century Adaptations Of Shakespeare and the Example of John Dennis 0.02362704364476641\n",
            "The Increase in Popularity of Shakespeare's Plays in the Eighteenth Century: A Caveat for Interpretors of Stage History 0.023611506188203686\n",
            "Front Matter                                       0.02344832739183233\n",
            "Why The Sweets Melted: A Study in Shakespeare's Imagery 0.023061565362891934\n",
            "Shakespeare's Plutarch                             0.022984026447597946\n",
            "The Background of Coriolanus                       0.022875005504980988\n",
            "Unbuilding the City: \"Coriolanus\" and the Birth of Republican Rome 0.022454627578657987\n",
            "Reviews of Current Stage and Screen Productions    0.022174458511299025\n",
            "Productions, Stage History                         0.021795474179287646\n",
            "Volume Information                                 0.02168194731544507\n",
            "Collections, Editions, and Translations            0.021336537606067085\n",
            "Volume Information                                 0.020322177350803463\n",
            "The Transmigration of the Crocodile                0.01988931787113327\n",
            "Shakespeare's Miracle Play                         0.01969990413509283\n",
            "Desolation and the Better Life: The Two Voices of Shakespearean Tragedy 0.01917201560704434\n",
            "The Paradox of Timon's Self-Cursing                0.01873816047612414\n",
            "Shakespeare In Los Angeles                         0.018594581808064885\n",
            "\"A Thing Unfirm\": Plato's Republic and Shakespeare's Julius Caesar 0.01814417782004373\n",
            "Shakespeare in the Periodicals 1700-1740: A Study of the Growth of a Knowledge of the Dramatist in the Eighteenth Century 0.01746643961366412\n",
            "Shakespeare: An Annotated Bibliography for 1951    0.014847551330729255\n",
            "The Autumn King: Remembering the Land in \"King Lear\" 0.013783564015996572\n",
            "â€œIf it be love indeedâ€: Transference, Love, and \"Anthony and Cleopatra\" 0.013049595626680557\n",
            "General Shakespeareana                             0.0074039083802376875\n",
            "Individual Works                                   0.003917476334300649\n"
          ]
        }
      ],
      "source": [
        "# Pick a unigram to discover its score across documents\n",
        "search_term = 'coriolanus'\n",
        "\n",
        "# Display a list of documents and scores for the search term\n",
        "\n",
        "matching = terms_to_docs.get(search_term)\n",
        "\n",
        "try: \n",
        "    for doc_id, score in sorted(matching, key=lambda x: x[1], reverse=True):\n",
        "        print(document_titles[doc_id].ljust(50), score)\n",
        "except:\n",
        "    print('Search term not found. Change the term or expand the corpus size.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgjMwDPx7RC6"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "gensim tfidf ATC revisited",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}